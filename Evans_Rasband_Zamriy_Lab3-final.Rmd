---
title: "Lab 3: Reducing Crime"
subtitle: "W203 Statistics"
author: "Luke Evans, Daniel Rasband, and Yulia Zamriy"
date: \today
output: pdf_document
fontsize: 11pt
geometry: margin=0.5in
---

```{r setup, include=FALSE, warning=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(knitr.table.format = "latex")
```

```{r, echo=FALSE}
# install.packages("viridisLite")
# install.packages("viridis")
# install.packages("Hmisc")
# install.packages("kableExtra")
# install.packages("car")
# install.packages("lmtest")
# install.packages("sandwich")
# install.packages("stargazer")
suppressMessages(library(knitr))
suppressMessages(library(kableExtra))
suppressMessages(library(Hmisc))
suppressMessages(library(reshape2))
suppressMessages(library(ggplot2))
suppressMessages(library(car))
suppressMessages(library(lmtest))
suppressMessages(library(sandwich))
suppressMessages(library(stargazer))
```

# An Analysis of Crime in North Carolina to Support Policy Decisions

## Introduction

Crime is expected to be a significant issue during the upcoming election in North Carolina. Using statistical techniques, this report attempts to provide data-driven insights into key determinants of crime in the state. A mixture of both long- and short-term policy suggestions will be included that address the factors that exacerbate crime, and that capitalize on those factors which act as suppressors.

## Exploratory Data Analysis

The data utilized to conduct this statistical analysis generally comes from the year 1987, with a single variable from 1980 (percent minority). Data is provided for most counties in North Carolina, and can be further grouped by region (West, Central and Other). Granularity below the county level is not available.

### Data Cleaning

Our initial exploration of the data has revealed several notable features. The information below provides the dimensions of the raw data: 25 variables and 97 rows.

```{r}
crime <- read.csv("crime_v2.csv", stringsAsFactors = FALSE)
dim(crime)
```

Of these observations, 6 rows are completely devoid of data and can be excluded.

```{r}
crime <- na.omit(crime)
```

There is also a duplicate record in this dataset:

```{r}
nrow(crime)
length(unique(crime$county))
```

Obeservation 91 and 90 are both for county 193:

```{r}
crime[duplicated(crime$county),"county"]
```

One of these rows is removed:

```{r}
crime <- crime[!duplicated(crime),]
dim(crime)
```

As a result the final dataset contains 90 observations and 25 variables.

It should be noted that there are 100 counties in North Carolina; therefore this dataset contains data for 90% of them. It is not possible to tell if the excluded counties are randomly distributed or share specific features that may bias this data set.

Counties range in population numbers from 15,000 people to over 1 million. The data provided has many abstracted values such as ratios and averages, but without the actual numbers relating to those abstractions, it can be hard to draw practical significance from conclusions as each county will be considered equal to any other. As electoral representation in general does not follow population density, there may be advantages to analyzing data at a county level only, but this limitation should be considered depending on the inference that is being generated.

One of the variables, the probability of conviction dimension, `prbconv`, was loaded as character and must be transformed to numeric data type in R. The following code makes this change:

```{r}
crime$prbconv <- as.numeric(as.character(crime$prbconv))
```

The variables are made up of several different types of number, many are interactions: Ratios, specifically the probability of arrest, conviction and prison sentence, the percent minority, young male, police and tax revenue per capita, and the ratio (mix) of face to face crimes to other types of crime. The means of several variables are provided for each county: a series of weekly wages in different business segments, and prison sentences in days. Finally, an indicator of the location of the county in the state is also provided, indicating West and Central regions. An "Other" region can be identified by difference. The `urban` variable also indicates whether the county is a “Standard Metropolitan Statistical Area”. Below is a table of variables including some summary statistics:

```{r}
crime_summary <- data.frame(t(mapply(summary, crime)))
crime_summary <- crime_summary[,c("Min.", "Mean", "Max.")]
crime_summary$Min. <- round(crime_summary$Min.,5)
crime_summary$Mean <- round(crime_summary$Mean,4)
crime_summary$Max. <- round(crime_summary$Max.,4)
kable(crime_summary, booktabs = TRUE) %>%
  kable_styling(font_size = 7)
```

From the above table, it can be seen that in several counties, the probability of arrest or the probability of conviction variables are greater than one, indicating that more arrests were carried out than crimes committed, or more convictions than those arrested. We explore boxplots below to determine if those values could be outliers.

```{r, fig.height = 2, fig.width = 6, fig.align="center"}
par(mfrow=c(1,2), mar=c(0,2,1,0))
boxplot(crime$prbarr,
        col = "darkgreen", cex.main = 0.6, cex.axis = 0.6, cex.lab = 0.6,
        main = "Probability of Arrest")
boxplot(crime$prbconv,
        col = "darkblue", cex.main = 0.6, cex.axis = 0.6, cex.lab = 0.6,
        main = "Probability of Conviction")
```

In case of probability of arrests, there is only one observation where the value is above 1, and it is significantly higher than the next closest value. This is observation 51, which has other features that will be covered later. It indicates that there have been more arrests than there have been crimes in a county. As this is time-limited data covering a single year, it is possible that crimes committed in the previous year and not recorded as a 1987 crime actually generated an arrest in 1987. Similarly, convictions may also have occurred in 1987, with the arrest relating to that conviction occurring in a prior period. It is not unfeasible that convictions for prior period arrests occur as the waiting time between being charged with an offense and a court date can be lengthy. Higher rates are an indication that a county is moving faster through its backlog.

Additionally, the table identifies some unusual features in some of the variables, including some significant outliers. Some of these outliers clearly appear to be inconsistent with the data and will be mentioned and corrected here; others may be more subtle and will be discussed as they are considered in models. Service industry wages and police per capita will be addressed in this section.

In the series of variables noting the weekly wages in a county, there is an exceptional value in one of the counties average wage, as seen in the below box-plot.

```{r, fig.height = 2, fig.width = 4, fig.align="center"}
par(mar=c(0,2,2,0))
boxplot(crime$wser, cex.main = 0.6, cex.lab = 0.6, cex.axis = 0.6,
        main = "Weekly Wage for Service Industry",
        ylab = "Wage in $")
```

This one value is not only over over 9 standard deviations from the mean (as seen below) of wser wages, but greater than any other weekly wage value in the state.

```{r}
 (max(crime$wser) - mean(crime$wser)) / sd(crime$wser)
```

This outlier may be an effect of the metric. The data does not provide a number of employees in each sector, and therefore it is impossible to compare these figures effecivly. This service business may be small, niche, and have highly paid staff such as an investment bank, and in a county with few other service industries, driving this sectors wages up. It is also not clear if this is the county where the wage is earned or the county where the wage earner lives.   The value is clearly not representative of the North Carolina population, however, and will be removed from our models. Only the service weekly wage value will be replaced by an imputed value; the rest of the observation will need to be preserved.

The result of a predictive model using the total of average weekly wages, with which the wages of the service sector are strongly correlated, is \$211 per week. This is not dissimilar from the mean of \$254 per week and therefore use of the mean as an imputed value is reasonable and simple. A new variable `wser_imp` is populated so that we do not lose the original values.

```{r}
crime$wser_imp <- ifelse(crime$wser > 2000, mean(crime[crime$wser < 2000,]$wser), crime$wser)
summary(crime$wser)
summary(crime$wser_imp)
```

The variable `density` appears to be on a different scale from its original description: *people per square mile*. Internet research reveals that the current average density in North Carolina is 187.6 *people per square mile*, while in the provided dataset the average value is 1.43 (for 1987). In addition, the population of North Carolina is listed at 6.4 million in 1987[^1], and North Carolina's area is listed as 53,819 square miles.[^2] Simple math shows the density of North Carolina in 1987 to be approximately 118.9 people per square mile. Comparison of county-level density between the provided dataset and current numbers strongly indicates that `density` in the 1987 `crime` dataset is *hundreds of persons per square mile*. This clarification will be important for model coefficient interpretation.

[^1]: https://www.statista.com/statistics/206270/resident-population-in-north-carolina/
[^2]: https://en.wikipedia.org/wiki/North_Carolina

The variable for police per capita (`polpc`) also has a notable outlier. This has generated some incongruent results with the rest of the dataset when segmented by region, as seen in the regression plots below.

```{r, fig.height = 4, fig.width = 5, fig.align="center"}
crime$region <- ifelse(crime$west == 1, "west", ifelse(crime$central == 1, "central", "other"))
ggplot(crime, aes(polpc, crmrte)) +
geom_point() +
facet_grid(region~.) +
geom_smooth(method = "lm", se = FALSE) +
  xlab("Police per capita") +
  ylab("Crime Rate") +
  ggtitle("Police per Capita vs. Crime Rate by Region")+
  theme(plot.title = element_text(size = 10),
        axis.title = element_text(size = 8),
        axis.text = element_text(size = 8))
```

It is clear that the impact of this observation is significant to the trend of police per capita on crime rate. There may be a valid reason for so many police per capita in one specific county, but as it is not representative of the rest of the population it will be removed. Additionally, according to governing.com[^3], police per population in Washington DC (where the highest concentration of police force might be expected) is 0.0065, which is still a lot fewer than this outlier.

[^3]: http://www.governing.com/gov-data/safety-justice/law-enforcement-police-department-employee-totals-for-cities.html

Based on this analysis, the outlier will be recoded with the mean of `polpc` in the West region:

```{r}
crime$polpc_imp <-
  ifelse(crime$polpc == max(crime$polpc),
         mean(crime[crime$west == 1 & crime$polpc < 0.009,]$polpc),
         crime$polpc)
summary(crime$polpc)
summary(crime$polpc_imp)
```

Furthermore, this outlier in police per capita occurs in the same observation as the upper outlier in probability of arrest.

```{r, fig.height = 4, fig.width = 5, fig.align="center"}
ggplot(crime, aes(polpc, prbarr)) +
  geom_point() +
  facet_grid(region~.) +
  geom_smooth(method = "lm", se = FALSE) +
  xlab("Police per capita, $") +
  ylab("Probability of arrest") +
  ggtitle(paste("Demonstration of relationship between Police per Capita",
                "and Probability of Arrest", sep = "\n")) +
  theme(plot.title = element_text(size = 10),
        axis.title = element_text(size = 8),
        axis.text = element_text(size = 8))
```

The unrepresentativeness of these outliers can be demonstrated when correlation between two variables is compared. The correlation changes from positive to negative if the observation 51 with the outlier is excluded:

```{r}
cat("Correlation with the outlier inlcuded:",
    cor(crime$polpc, crime$prbarr), "\n")
cat("Correlation with the outlier excluded:",
    cor(crime[-51,]$polpc, crime[-51,]$prbarr), "\n")
```

Therefore, a new variable has been created for the probability of arrest with the mean of the variable in the West becoming the imputed value for the outlier:

```{r}
crime$prbarr_imp <-
  ifelse(crime$prbarr > 1,
         mean(crime[crime$west == 1 & crime$prbarr < 1,]$prbarr),
         crime$prbarr)
summary(crime$prbarr)
summary(crime$prbarr_imp)
```

The observation in question is county 115, observation 51. This county has the probability of arrest of over 1, and the exceptional police per capita. Furthermore, this county has the lowest crime rate, the highest average sentence, the lowest minority percentage and a conviction to arrest rate of over 1. It is an interesting county to be aware of as it does not appear to be representative of the state as a whole, and therefore some of the broader state wide policy reccomendations may not be as effective there.

An additional data issue was identified for a county where both _west_ and _central_ variables are equal to 1:

```{r}
table(crime$west, crime$central)
```

It is possible that a large county may straddle the regions. Having investigated this county and compared it to the averages of all variables for $west = 1$, $central=1$ and $west=central=0$, the available characteristics did not make it obvious in which region it belongs. However, it should not be excluded from our analysis as it appears a valid data point in all other respects. A flag variable is created that will allow it to be excluded if necessary:

```{r}
crime$exclude <- ifelse(crime$county %in% c(71), 1, 0)
table(crime$exclude)
```

Though other variables appear to have exceptional values or outliers (particularly probability of arrest and the percent young male), none are as clear. These outliers will be addressed during the development of the models as appropriate and with due consideration for the practical significance and the leverage and influence they have on the models developed.

### Correlations

To conclude the initial data exploration, an easy-to-reference correlation heatmap has been developed for quick identification of positive or negative correlations between variables in the data set.

```{r, fig.align="center"}
ind_variables <- c(
  "crmrte", "prbarr_imp", "prbconv", "prbpris", "avgsen", "polpc_imp",
  "density", "taxpc", "west", "central", "urban", "pctmin80", "wcon", "wtuc",
  "wtrd", "wfir", "wser_imp", "wmfg", "wfed", "wsta", "wloc", "mix", "pctymle"
)

cor_mat <- round(cor(crime[,ind_variables]),2)
get_upper_tri <- function(cor_mat){
    cor_mat[lower.tri(cor_mat)]<- NA
    return(cor_mat)
}
cor_mat_upper <- get_upper_tri(cor_mat)
cor_mat_upper2 <- melt(cor_mat_upper, na.rm = TRUE)
cor_mat_upper2[cor_mat_upper2$value == 1,]$value <- 0

ggplot(data = cor_mat_upper2, aes(Var1, Var2, fill = value)) +
  geom_tile() +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white",
                        midpoint = 0, limit = c(-1,1), space = "Lab",
                        name = "Correlation") +
  theme_minimal() +
  scale_x_discrete(position = "top") +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, size = 8, hjust = 0),
        axis.title.x=element_blank(),
        axis.title.y=element_blank(),
        plot.title = element_text(size = 10)) +
  coord_fixed() +
  ggtitle("Correlation Matrix")
```

Based on the above matrix a few important patterns have been identified:

 - `density` has the strongest correlation with crime rate. It is one of the most important variables to test in the models as there are a number of factors, discussed in omitted variables, that are included in this factor. Its impact must be considered.
 - All wages variables are positively correlated with each other. Hence, it would create challenges for keeping multiple variables in the model. Additionally, the understanding of the interpretation of the wages variables poses challenges, as discussed above.
 - `density` has a strong positive correlation with `urban` indicator. This relationship is as expected. Given that `density` has higher correlation with `crmrte`, including density will be satisfactory to control for the level of urbanization in the county in the models.
 - The level of policing, or police per capita, is positivly correlated with crime. This impact is not expected as an increase in policing might logically be associated with a reduction in crime. However, the reaction to a high crime rate would be to increase policing to help control crime. However, it is unclear from this single-year-based dataset whether increase in policing is reducing the crime rate as compared to prior periods. Furthermore, the presence of police may make it more likely to report crime, increasing the crimes reported above other counties.

### Summary of variables

The table below summarizes all variables in the dataset, and includes the expected impact of each on the dependent variable, crime rate, along with the actual correlation. Also included, as a framework for the analysis, is an assessment of the rapidity at which policy could be enacted and be effective.

 - **Short term** refers to policies that could be implemented quickly, within the months preceeding and immedietly after an election. The support and lobbying for judges with perspectives that would support policies relating to custodial terms and their length, for example.
 - **Medium term** policies are those that take some planning and financing, but which can be implemented and results demonstrated during an electoral term. This may include recruiting and training police officers, or upgrades of crime investigation equipment.
 - **Long term** policies would be those needing sustained effort or funding, and results will be expected outside of the duration of a single term. These may be developing incentives and strategies to manage population density.

```{r, echo = TRUE}
var_labels <- c("crimes committed per person", "probability of arrest",
  "probability of conviction", "probability of prison sentence",
  "avg. sentence, days", "police per capita", "100s of people per sq. mile",
  "tax revenue per capita", "=1 if in western N.C.", "=1 if in central N.C.",
  "=1 if in SMSA", "perc. minority, 1980", "weekly wage, construction",
  "wkly wge, trns, util, commun", "wkly wge, whlesle, retail trade",
  "wkly wge, fin, ins, real est", "wkly wge, service industry",
  "wkly wge, manufacturing", "wkly wge, fed employees",
  "wkly wge, state employees", "wkly wge, local gov emps",
  "offense mix: face-to-face/other", "percent young male")

impact <- c("Dependent", "Negative" , "Negative", "Negative", "Negative",
  "Negative", "Positive", "Negative", "Unclear", "Unclear", "Unclear",
  "Unclear", "Negative","Negative","Negative", "Negative", "Negative",
  "Negative", "Negative", "Negative", "Negative", "Unclear","Positive")

control <- c("NA", "Medium Term", "Medium Term", "Short Term", "Short Term",
  "Medium Term", "Long Term", "Long Term",
  "No", "No", "No", "Long Term",
  "Medium Term", "Medium Term", "Medium Term",
  "Medium Term", "Medium Term", "Medium Term", "Medium Term",
  "Short Term", "Medium Term", "No", "Long Term")

cor_w_crimerate <- round(cor(crime[,ind_variables])[1,],2)
desc <- data.frame(ind_variables, var_labels, impact, cor_w_crimerate, control,
                   row.names = NULL)
colnames(desc) <- c("Explanatory Variables", "Explanation",
  "Expected Impact on Crime Rate", "Correlation w/ Crime Rate",
  "Potential Policy Impact Timeframe")

kable(desc, booktabs = TRUE, align = c("llccc")) %>%
  kable_styling(latex_options = c("scale_down"), full_width = FALSE) %>%
  row_spec(0, bold = TRUE) %>%
  column_spec(1, width = "7em") %>%
  column_spec(3, width = "10em") %>%
  column_spec(4, width = "8em") %>%
  column_spec(5, width = "10em")
```

## The Model Building Process

### Overview

As we are moving into model building section of the report, let’s outline our objective: identify the impact of causal variables on crime rate to build crime-fighting policies. What are the causal variables of interest in this case? We hypothesize that in this dataset there are two variables that cause the crime rate to increase/decrease: probability of arrest and probability of conviction. The third probability variable, `prbpris`, has a weak correlation with crime rate. Most likely this is due to the fact that prison sentence is far enough from the act of a crime to be ineffective in altering criminal behavior.

Our first model will be developed with these two variables along with two control variables that will help us to get unbiased estimates of our main variables of interest (explained in the appropriate section).

Our second model will expand on the first one. We will add variables that help us improve the fit of the model without interacting significantly with our main causal effects. The added variables also make sense in terms of interpretability.

The third model will contain all provided variables (except county and year). This model will be used to demonstrate that our model 2 is robust.

The last part of this section will focus on the residuals of all three models.

### Dependent variable

Our dependent variable is crime rate (`crmrte`), which is defined as "Crimes committed per person."

After careful consideration, and in order for us to understand the impact of our main causal effects (probability of arrest and probability of conviction) on crime rate, we decided to transform our dependent variable by taking a natural log.

Since this variable is a ratio (crimes per person), hypothetically it can vary between 0 and 1 (though it’s highly unlikely that one could find a county with such a high crime rate). This makes it not very suitable for OLS because this method can predict values outside the 0 to 1 range. The natural log will help us only with part of the problem (avoiding negative values in the prediction of actual crime rate). There's one caveat: in our dataset, the crime rate variable is never equal to zero. Hence, transformation is straightforward. However, since zero is a real possible value, we would need to watch out for those values while transforming crime rate in different datasets.

This transformation would also allow us to interpret the coefficients of predictive factors as semi-elasticities: if probability of arrest goes up by one point, then the crime rate decreases by `100*y%` (assuming our stated hypothesis is true and the probability of arrest `prbarr` has a negative effect). If we were to keep the variable as is, we would interpret the coefficient for `prbarr` as the following: if probability of arrest goes up by one point, then the crime rate decreases by `y` crimes per person. However, this interpretation does not allow us to judge the practical significance of the effect (is `y` big or small?).

Let's take a look at histograms for `crmrte` (as it is and transformed):

```{r, fig.height = 2, fig.width = 7, fig.align="center"}
par(mfrow=c(1,2), mar=c(2,4,1,0))
hist(crime$crmrte,
     breaks = 15, xlim = c(0,0.1), ylim = c(0,17), col = "darkblue",
     cex.main = 0.6, cex.axis = 0.6, cex.lab = 0.6,
     xlab = "Crime Rate",
     main = "Histogram for Crime Rate")
hist(log(crime$crmrte),
     breaks = 15, xlim = c(-6,-2), col = "darkgreen",
     cex.main = 0.6, cex.axis = 0.6, cex.lab = 0.6,
     xlab = "Log of Crime Rate",
     main = "Histogram for Log of Crime Rate")
```

Based on the above charts, `crmrte` is skewed towards the right tail (a number of counties have large crime rates). The log of `crmrte`, on the other hand, looks normally distributed. This definition of the dependent variables will help us build a model with a better fit.

### Main control variables

Our primary focus in this analysis is on two variables: `prbarr` and `prbconv`. These two variables, the probability of arrest and the probability of conviction respectively, have relatively high correlations with crime rate and have the potential to be influenced by political action. We will try to understand how probability of arrest `prbarr` and probability of conviction `prbconv` impact crime rate. If they are strong causal factors, we can capitalize on them, developing policies that help us lower crime rates across North Carolina.

Earlier in this report, we hypothesised that these two variables would have a negative impact on our dependent variable: the higher the probabilities of arrest and conviction, the lower the crime rate. Before building a model with these two variables, however, we want to make a case for including two more variables in our first model: `density` and `west`.

First, let’s consider average crime rate by region (we recoded the third region as "other" for analysis purposes):

```{r}
crime$region <- ifelse(crime$west == 1, "west",
                       ifelse(crime$central == 1, "central", "other"))
aggregate(crmrte ~ region, data = crime, mean)
```

Based on the table above, and as discussed in the EDA, crime rate in the West region is lower than in the Central and Other regions. We therefore need to control for regionality in order to get an unbiased read on the two selected probability variables.

Additionally, some comparison of group means reveals a 25% difference in percent minority between the western region and others. While this may be related to the presence of minorities, it is more likely to be the product of a bivariate relationship with a 3rd factor such as poverty. Perhaps migrants are more attracted to wealthy or more populated areas so as to find employment opportunities.

```{r}
pctmin_per_region <- lm(pctmin80 ~ west, data = crime)
summary(pctmin_per_region)$coefficients
```

We should keep the above in mind while interpreting our models.

On the other hand, density has the highest correlation with crime rate (0.73). And the chart below shows clear support for a strong linear relationship between the two variables:

```{r, fig.height = 3, fig.width = 5, fig.align="center"}
ggplot(crime, aes(density, crmrte)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  ggtitle("Crime Rate vs. Density")+
  xlab("Density") +
  ylab("Crime Rate") +
  theme(plot.title = element_text(size = 10),
        axis.title = element_text(size = 8),
        axis.text = element_text(size = 8))
```

We also know that `west` and `density` have a different relationship with `crmrte`; even though crime rate is the lowest in the West, density is the highest in the Central region. Therefore, we need both `west` and `density` in our initial model to get unbiased estimates of `prbarr` and `prbconv`.

```{r}
aggregate(density ~ region, data = crime, mean)
```

**Note**: we tested *central* and *urban* in our models and they were not significant predictors for crime rate.

### Model #1

Our first model contains four variables: `density`, `west`, `prbarr`, `prbconv`.

Since the two probability variables are on the scale from 0 and 1 (except the outliers), we will multiply them both by 100 to change the scale to 0 to 100. This will allow the interpretation to be the percent change in crime rate per one point change in probability.

```{r}
crime$prbarr_imp100 <- 100 * crime$prbarr_imp
crime$prbconv100 <- 100 * crime$prbconv
```

```{r}
model1.ind_vars <- c("density", "west", "prbarr_imp100", "prbconv100")
model1.formula <- as.formula(paste("log(crmrte) ~",
                                   paste(model1.ind_vars, collapse = " + "),
                                   sep = " "))
model1 <- lm(model1.formula, data = crime)
model1a <- lm(model1.formula, data = crime[crime$exclude == 0,])
```

```{r, echo = TRUE}
interpret1 <- c("","For an increase of one unit (100 people per square mile) in density,
                crime rate increases by 13.7% when everything else stays the same",
                "Crime rate in the West is 40.1% lower than in Central and Other
                regions on average (and controlling for all other included variables)",
                "For approximately each percentage increase in probability of arrest,
                crime rate decreases by 1.68%",
                "For approximately each percentage increase in probability of conviction,
                crime rate decreases by 0.68%")

coef1 <- data.frame("Model 1 Coefficients" = round(model1$coefficients, 4),
                    "Interpretation" = interpret1)

kable(coef1, booktabs = TRUE) %>%
  kable_styling(font_size = 8, full_width = FALSE) %>%
      column_spec(3, width = "35em")
```

Our model is consistent with our initial hypothesis: both probability variables have a negative impact on crime rate. Moreover, a one-point change in probability of arrest has more than two times higher impact on crime rate than a one-point change in probability of conviction. This confirms our hypothesis that probability of arrest has a stronger effect on crime rate because it's closer to the act of a crime (being arrested is easier to relate to than being convicted).

The adjusted $R^2$ for this model is 67.2% which means a lot of the the variations are explained by this model:

```{r}
summary(model1)$adj.r.squared
```

All of the coefficients are highly statistically significant when we look at heteroskedastic-robust errors:

```{r}
coeftest(model1, vcov = vcovHC, level = 0.05)
```

One last check is to compare model results for the full dataset and for the one excluding county #71 to ensure that it is not impacting the model (where $west=central=1$):

```{r}
compare1 <- data.frame(cbind(round(coeftest(model1, vcov = vcovHC, level = 0.05)[,1],4),
                             round(coeftest(model1a, vcov = vcovHC, level = 0.05)[,1],4),
                             round(coeftest(model1, vcov = vcovHC, level = 0.05)[,3],1),
                             round(coeftest(model1a, vcov = vcovHC, level = 0.05)[,3],1)))
colnames(compare1) <- c("Est. w/ #71", "Est. w/o #71", "t.val w/ #71", "t.val w/o #71")
compare1
```

As we can see, there is a slight change in the coefficient for $west$. However, this change is less than 3%. Hence, we can conclude that this county doesn't influence our results and we will keep it in.

### Model #2

We tested the other variables in the dataset for their relationship to crime rate (using correlations). We decided to add the following variables: `polpc`, `pctmin80`, and an interaction of `west` and `polpc`.

As discussed in the correlation section, police per capita is not only highly correlated with crime rate, but it does seem to have a direct link to crime. While the variable is necessary for control purposes and improves the fit of the model, formulating policies using this variable is not advised.

The percent of minorities also helps with model fit. It is hard to hypothesize why correlation with crime rate is positive. Do poorer counties have larger minority populations? In this case, personal income would be a confounding variable that we don’t have. Or do counties with more minorities have more gangs? This would also be a confounding variable. Percent minorities will be used as representative of omitted factors.

Before adding these variables, we decided to transform the `polpc` variable by taking its log. We perform this transformation for two reasons: there is a stronger correlation between the log of police per capita and the log of the crime rate variable than that of the raw values or of the log of the crime rate and the raw police per capita. This tells us that there is a better correlation between percent changes in the two variables than the raw changes. Performing this transformation also improves the quality of our regression model. The transformation is performed here:

```{r}
crime$polpc_imp.ln <- log(crime$polpc_imp)
```

Correlation is strongest between the logs of both variables:

```{r}
descriptions <- c(
  "log(crmrte), log(polpc)",
  "log(crmrte), polpc",
  "crmrte, polpc"
)
correlations <- c(
  round(cor(crime$polpc_imp.ln, log(crime$crmrte)), 4),
  round(cor(crime$polpc_imp, log(crime$crmrte)), 4),
  round(cor(crime$polpc_imp, crime$crmrte), 4)
)
crmrte.polpc.cor <- data.frame(descriptions, correlations)
kable(crmrte.polpc.cor, col.names = c("Variables", "Correlation"),
      booktabs = TRUE)
```

We also combine `west` and the transformed `polpc` (`polpc_imp.ln`) by multiplying them. The interaction is necessary as the police per capita in the West region has a much lower correlation with crime rate than police per capita in the other regions, as is shown here:

```{r}
region <- c("West",
            "Central",
            "Other")

region_cor <- c(
  round(cor(log(crime[crime$region=="west",]$crmrte),
            crime[crime$region=="west",]$polpc_imp.ln),2),
  round(cor(log(crime[crime$region=="central",]$crmrte),
            crime[crime$region=="central",]$polpc_imp.ln),2),
  round(cor(log(crime[crime$region=="other",]$crmrte),
            crime[crime$region=="other",]$polpc_imp.ln),2)
)
cor.by.region <- data.frame(region, region_cor)
kable(cor.by.region, col.names = c("Region", "Correlation"),
      booktabs = TRUE)
```

For unknown reasons, the relationship between `crmrte` and `polpc` varies significantly by region. In particular, it is weak in the Western region, and very strong in the Central. This could be explained by different policing strategies, as well as their effectiveness. However, we do not have any variables to control for that. The best we can do is to create an interaction term between `west` and `polpc` as a proxy for omitted variables.

Now, to the actual model:

```{r}
model2.ind_vars <- c("density", "west", "prbarr_imp100", "prbconv100",
                     "polpc_imp.ln", "pctmin80", "I(west * polpc_imp.ln)")
model2.formula <- as.formula(paste("log(crmrte) ~ ",
                                   paste(model2.ind_vars, collapse = " + "),
                                   sep = ""))
model2 <- lm(model2.formula, data = crime)
```

```{r, echo = TRUE}
interpret2 <- c(
  "",
  "(Before: 0.14): The effect of density has decreased as we are controlling for
  more factors. For each unit (100 persons per square mile) increase in density,
  crime rate increases by 8.9%",
  "(Before: -0.40): This coefficient cannot be interpreted by itself
  as it is now part of interaction with police per capita.
  See explanation below",
  "(Before: -0.0168): The probability of arrest has a
  stronger effect.
  A single percentage increase in the probability of arrest results
  in a 2.02% decrease in the crime rate",
  "(Before: -0.0068): The effect of the probability of conviction
  has also increased slightly. For approximately each percentage increase in the
  probability of arrest, crime rate decreases by 0.74%",
  "This coefficient indicates that a 1% increase in police per capita is associated
  with a 0.64% increase in crime rate in all regions but West",
  "This coefficient indicates that 1 percent point increase in the minority
  population means a 0.99% increase in crime per capita",
  "See explanation below")

coef2 <- data.frame("Model 2 Coefficients" = round(model2$coefficients, 4),
                    "Interpretation" = interpret2)

kable(coef2, booktabs = TRUE) %>%
  kable_styling(font_size = 8, full_width = FALSE) %>%
      column_spec(3, width = "35em")
```

The interaction term (`I(west * polpc_imp.ln)`) is harder to interpret. It applies to the West region only. That means that the `polpc_imp.ln` coefficient of 0.6358 applies only to Central and Other regions. In the West the coefficient for `polpc_imp.ln` is actually 0.0257 (0.6358 - 0.6101) or for each percent change in police per capita in the West, there is only a 0.0257% change in crime rate. This value is relatively close to zero and implies no practically significant relationship between the two variables in that region. This is supported by correlations we examined earlier in this section.

As for the `west` coefficient, it also cannot be interpreted in isolation because setting `polpc_imp.ln` to zero does not make practical sense. If on the other hand, we use the mean of `polpc_imp.ln` for the West region then the partial effect for `west` is as follows:

```{r}
mean_polpc <- mean(crime[crime$region=="west",]$polpc_imp.ln)
coef_west_polpc <- model2$coefficients["I(west * polpc_imp.ln)"]
coef_west <- model2$coefficients["west"]
coef_west + coef_west_polpc*mean_polpc
```

This second model remains consistent with our initial hypothesis. The overall predictive strength of the model has also increased. The adjusted $R^2$ for this model is 80.2%, which is 12.9 percentage points higher than our first model:

```{r}
summary(model2)$adj.r.squared
```

All of the coefficients are statistically significant when we look at heteroskedasticity-robust errors:

```{r}
coeftest(model2, vcov = vcovHC, level = 0.05)
```

Furthermore, the p-value for the F-statistic (derived below) is well below the 1% critical value. This indicates that we can reject the null hypothesis that the additional variables added to model 2 versus model 1 (police per capita, percent minority and the interaction between the Western region and police per capita) jointly have no effect on crime rate.

```{r}
waldtest(model2, model1, vcov = vcovHC)
```

### Model #3 - All Variables

Our last model includes all variables, including our imputed variables. We transform all wage variables by taking their natural log. This will allow us to interpret the coefficients as elasticities instead of using absolute wage changes.

```{r}
wage.vars <- c("wcon", "wtuc", "wtrd", "wfir", "wser_imp", "wmfg", "wfed",
               "wsta", "wloc")
wage.vars.ln <- mapply(function(var.name) paste(var.name, ".ln", sep=""),
                       wage.vars)
crime[, wage.vars.ln] <- log(crime[, wage.vars])
```

And then we create our third model, which includes all of variables, transformed as needed:

```{r}
model3.ind_vars <- c("prbarr_imp100", "prbconv100", "prbpris", "avgsen",
                     "polpc_imp.ln", "I(west * polpc_imp.ln)", "density", "taxpc",
                     "west", "central", "urban", "pctmin80", "wcon.ln",
                     "wtuc.ln", "wtrd.ln", "wfir.ln", "wser_imp.ln", "wmfg.ln",
                     "wfed.ln", "wsta.ln", "wloc.ln", "mix", "pctymle")
model3.formula <- as.formula(paste("log(crmrte) ~ ",
                                   paste(model3.ind_vars, collapse = " + "),
                                   sep = ""))
model3 <- lm(model3.formula, data = crime)
summary(model3)$adj.r.squared
```

Despite adding a lot more variables, the $R^2$ of the all-inclusive regression model went up only to 83.0% (from 80.2% in model 2). The Wald test also reveals that if we use 1% as a critical value, we fail to reject the null hypothesis that variables added to model 3 jointly have no effect on crime rate.

```{r}
waldtest(model3, model2, vcov = vcovHC)
```

Now let's compare the coefficients in this model to the other two models:

```{r, warning=FALSE}
se.model1 <- sqrt(diag(vcovHC(model1)))
se.model2 <- sqrt(diag(vcovHC(model2)))
se.model3 <- sqrt(diag(vcovHC(model3)))
stargazer(model1, model2, model3,
          type = "text", omit.stat = "f",
          se = list(se.model1, se.model2, se.model3),
          star.cutoffs = c(0.05, 0.01, 0.001),
          no.space = TRUE, align = TRUE)
```


**This table demonstrates the following:**

 - Our main variables of interest `prbarr` and `prbconv` have robust estimates in all models. Moreover, `prbarr` coefficient is consistently higher than for `prbconv`. Hence, it is more likely to cause crime rate to change.
 - The coefficient for `density` decreases from model 1 to model 2 as we introduce more variables that likely interact with it (for example, `west`). However, its standard error remains small enough for the `density` effect on crime rate to be significant. In model 3, however, its standard error increases most likely due to strong interaction with added variables especially `urban` and the wages.
 - `polpc` maintains its statistically significant coefficient with low standard error in model 3.
 - `pctmin80` is also robust as its coefficient stays statistically significant in model 3.
 - All other variables are not statistically significant in model 3, except `pctymle`. However, as we tested this variable in model 2, its standard error was too high. We can conclude that this variable is not robust enough to keep it in our main model.

### CLM Assumption Analysis

In this section we discuss the classic linear model (CLM) assumptions of our models. Since model 2 has the highest number of significant coefficients, we will include a full explication of the assumptions for that model, referencing the other models for comparison or when surprising deviations are apparent.

#### MLR.1: Linearity in Parameters

For all three models, we assume linearity in parameters by default. We have made natural log transformations to the crime rate, police per capita, and wage variables to capture nonlinear relationships between those variables within a linear framework. This does not violate MLR.1.

#### MLR.2: Random Sampling

Our analysis of the random sampling assumption applies to all three models. Since the observations in the data include 90% (90/100) of all North Carolinian counties, it would be difficult to argue that the observations are not representative of the population. That said, there is always a possibility that the data set could include all counties except those with high density, high crime, low crime, or some other exceptional joint quality. Based on the variances of observations in the various variables, however, it appears that a wide variety of counties are represented, and are in fact representative of the population. For example, the natural log of `crmrate` is approximately normally distributed, and the untransformed `crmrte` variable ranges from close to zero (about 6 crimes per 1000 people) up to almost one hundred crimes per one thousand people. Many other variables have a more-or-less reasonable variation and distribution.

```{r}
cat(paste(
  paste("Minimum crime rate:", round(min(crime$crmrte) * 1000), "per 1000 people", sep = " "),
  paste("Maximum crime rate:", round(max(crime$crmrte) * 1000), "per 1000 people", sep = " "),
  sep = "\n"
))
```

One thing that seems to indicate a slight bias in the sampling is the region. It is apparent that there are fewer counties represented in the west than in other regions:

```{r}
cat(paste(
  paste("West:", nrow(subset(crime, west == 1))),
  paste("Central:", nrow(subset(crime, central == 1))),
  paste("Other:", nrow(subset(crime, central == 0 & west == 0))),
  sep = "\n"
))
```

This is actually a fair representation of North Carolina, however, since the western region of the state is narrower than the central and eastern regions, meaning there are actually fewer counties in the western region.

#### MLR.3: No Perfect Collinearity

If all three regions ("West", "Central", and "Other") were used in the model, then there would be perfect multicollinearity, but R would remove one of them regardless. Our models do not include variables that would violate this assumption.

#### MLR.4: Zero Conditional Mean

The assumption of zero conditional mean of errors seems to be violated in models #1 and #2, as indicated by a seagull-silhouette-shaped lines in the residuals vs. fitted plots show here:

```{r, fig.height = 3, fig.width = 7, fig.align="center"}
par(mfrow=c(1,2), mar=c(2,4,2,0))
plot(model1, which = 1, cex.main = 0.8, cex.axis = 0.6, cex.lab = 0.6,
     main = "Model 1:\nResiduals vs. Fitted", caption = "")
plot(model2, which = 1, cex.main = 0.8, cex.axis = 0.6, cex.lab = 0.6,
     main = "Model 2:\nResiduals vs. Fitted", caption = "")
```

For model 2, observation #51, again, seems to be pulling the errors away from 0 more than any other observation. This is the same observation where we replaced `prbarr` and `polpc` with sample means. However, we still observe strong impact observation #51 on conditional mean of errors. Below is the comparison of key variables means in the West region and observation #51 (which is in the West region):

```{r}
model2a.ind_vars <- c("density", "west", "prbarr", "prbconv",
                     "polpc", "pctmin80")
county_check <-
  data.frame(t(rbind(round(mapply(mean, crime[crime$west == 1,c("crmrte",model2a.ind_vars)]),4),
      crime[51,c("crmrte",model2a.ind_vars)])))
colnames(county_check) <- c("Averages in West", "Obs #51")
county_check$Diffrence <- paste(round(100*(county_check$`Obs #51`/ county_check$`Averages in West`-1),1),"%",sep="")
county_check
```

It appears that this observation deviates greatly in all key variables from the mean. Moreover, observation #51 contains:

 - the lowest `crmrte` in the entire dataset
 - the highest `polpc` and `prbarr` (which we replaced with means for reasons stated above)
 - the lowest `pctmin80` in the entire dataset

We don't have enough information to judge if this county is an exception or a data entry error. However, it exhibits characteristics of an outlier in our model 2. We should check the assumption #4 for the model without this observation:

```{r, fig.height = 3, fig.width = 7, fig.align="center"}
model2a <- lm(model2.formula, data = crime[-51,])
par(mfrow=c(1,2), mar=c(2,4,2,0))
plot(model2, which = 1, cex.main = 0.8, cex.axis = 0.6, cex.lab = 0.6,
     main = "Model 2 full dataset:\nResiduals vs. Fitted", caption = "")
plot(model2a, which = 1, cex.main = 0.8, cex.axis = 0.6, cex.lab = 0.6,
     main = "Model 2 excluding obs #51:\nResiduals vs. Fitted", caption = "")
```

It appears that zero-conditional mean is closer to 0 on the lower end of the dependent variable. However, this assumption still seems to be violated. Including more variables as tested in model 3 did not improve the situation. One of the potential reasons is that we are missing variables that would help explain extreme crime rates (very low and very high). Additionally, this violation is not driven by log transformation of our dependent variable because the models with untransformed crime rates performed significantly worse in terms of assumptions 4 and 5.

Hence, our hypothesis is that omitted variables are main contributors to the violation. The details are discussed in the corresponding section. 

#### MLR.5: Homoskedasticity

In the Scale-Location plot, again observation #51 is causing some heteroskedasticity in residuals for model 2. In model 1, the standard deviation of residuals, on the other hand, looks constant.

```{r, fig.height = 3, fig.width = 7, fig.align="center"}
par(mfrow=c(1,2), mar=c(2,4,2,0))
plot(model1, which = 3, cex.main = 0.8, cex.axis = 0.6, cex.lab = 0.6,
     main = "Model 1:\nScale-Location", caption = "")
plot(model2, which = 3, cex.main = 0.8, cex.axis = 0.6, cex.lab = 0.6,
     main = "Model 2:\nScale-Location", caption = "")
```

However, none of the observations stand out as outliers, even #51 in the Cook's distance charts below.

```{r, fig.height = 3, fig.width = 7, fig.align="center"}
par(mfrow=c(1,2), mar=c(2,4,2,0))
plot(model1, which = 5, cex.main = 0.8, cex.axis = 0.6, cex.lab = 0.6,
     main = "Model 1:\nResiduals vs. Leverage", caption = "")
plot(model2, which = 5, cex.main = 0.8, cex.axis = 0.6, cex.lab = 0.6,
     main = "Model 2:\nResiduals vs. Leverage", caption = "")
```

Again, we can check this assumption on the dataset with excluded observation #51:

```{r, fig.height = 3, fig.width = 7, fig.align="center"}
par(mfrow=c(1,2), mar=c(2,4,2,0))
plot(model2, which = 3, cex.main = 0.8, cex.axis = 0.6, cex.lab = 0.6,
     main = "Model 2 full dataset\nScale-Location", caption = "")
plot(model2a, which = 3, cex.main = 0.8, cex.axis = 0.6, cex.lab = 0.6,
     main = "Model 2 excluding obs #51:\nScale-Location", caption = "")
```

It appears that excluding this observation removes some of the heteroskedasticity in the residuals. At this point we can check if our model 2 changes when observation #51 is excluded:

```{r}
coef_compare <- data.frame(
  cbind(round(coeftest(model2, vcov = vcovHC, level = 0.05)[,1],4),
      round(coeftest(model2a, vcov = vcovHC, level = 0.05)[,1],4),
      round(coeftest(model2, vcov = vcovHC, level = 0.05)[,3],2),
      round(coeftest(model2a, vcov = vcovHC, level = 0.05)[,3],2)))
colnames(coef_compare) <- c("Est. Full Dataset",
                            "Est. w/o obs 51",
                            "t-stat Full Dataset",
                            "t-stat w/o obs 51")

coef_compare.ratio <- coef_compare$`Est. w/o obs 51` / coef_compare$`Est. Full Dataset` - 1
coef_compare$Estimate.Diff <-
  paste(round(100 * (coef_compare.ratio), 1), "%", sep = "")

kable(coef_compare, booktabs = TRUE) %>%
  kable_styling(font_size = 8,
                full_width = FALSE) %>%
  row_spec(0, bold = TRUE)
```

Our estimates change by 1-8% on average and all t-stats remain above 2 (except the intercept). This indicates that our model 2 is robust to outliers and it can be used for deriving policies to reduce crime rate.

#### MLR.6: Normality of Errors

Our dataset contains more than 30 observations (90 to be precise), so we can apply CLT to its residuals and assume they are normal. We still investigate the histograms for models 1 and 2 below. Neither of them fit into the normal distribution particularly well, but they don't have particularly strong skews either.

```{r, fig.height = 2, fig.width = 5, fig.align="center"}
par(mfrow=c(1,2), mar=c(2,4,2,0))
hist(model1$residuals,
     breaks = 15,  col = "darkblue", xlim = c(-1,1),
     cex.main = 0.8, cex.axis = 0.6, cex.lab = 0.6, xlab = "",
     main = "Model 1 Residuals")
hist(model2$residuals,
     breaks = 15, col = "darkgreen", xlim = c(-1,1),
     cex.main = 0.8, cex.axis = 0.6, cex.lab = 0.6, xlab = "",
     main = "Model 2 Residuals")
```

Overall, the residual analysis shows that our models have some issues with fitting certain values of crime rate (on the high end). We can also see some heteroskedasticity in residuals caused by a few observations.

## Omitted Variable Analysis

```{r}
omv_items <- c(
  "Drug and alcohol abuse levels","", "Unreported crime", "", "Recidivism", "",
  "Unemployment levels", "", "Education levels", "", "Strength of community", "",
  "Income inequality"
)

omv_desc <- c(
  "The presence of drug and alcohol problems in a community is a significant
  contributing factor to crime rates in many areas", "",
  "The stigma of some crimes for victims within a community, the feeling that nothing will
  be done to catch the perpetrators (or perhaps vigilante justice) may lead to crimes in
  some areas being under-reported. Sexual assaults specifically can be difficult for
  victims to report for fear of social isolation or reprisals in smaller communities.
  The presence of gangs, undocumented immigrants, those poor and uninsured, or
  where local judicial services are overwhelmed and unavailable may be a cause in
  some more urban areas", "",
  "There have been several studies that suggest that someone who has committed a crime
  in the past is more likely to commit crimes in the future.[^4] The proportion of people
  with prior convictions in a county could be an additional driver that would impact
  crime rate", "",
  "The employment level in a county are likely to have an impact on crime rate", "",
  "The level of education in a county could be an indicator of some crimes", "",
  "Strong community ties, generally in rural areas, can have a suppressing effect on crime.
  The strength of community can also cause crimes to be unreported and dealt with through
  informal means", "",
  "Inequality of wealth can be a driver of crime. Regardless of average wage value, if the
  difference in wages is generally high, i.e. if there are disparities in the distribution
  amongst the population, crimes will tend to increase"
)

omv_inf <- c(
  "There is an expectation that less affluent communities in urban areas would be most
  impacted, which may explain some of the higher rates of crime in more densely populated
  counties and bias the coefficient of 'density' in our model. However, we have not
  recommended policy decisions based on density", "",
  "May impact rural areas and pockets of urban areas with impacts that would lower those
  coefficients. Additionally, the greater the police presence, the more likely crimes are
  to be reported which may be artificially increasing crimes recorded in heavily policed
  areas. While our model does include the policing per capita, no policy decisions
  are based upon it","",
  "It is unclear where this bias may have the strongest effect, but is unlikely to be in
  the most affluent areas with the higher wages and taxes per capita. If so, this could
  be artificially raising the coefficient of such variable. As these variables are not
  included in the model, this will not impact policy recommendations but may be a factor
  to consider in further study","",
  "Unemployment is usually higher in the young and minorities. The higher positive
  coefficients of percent minority variable in our models will include some amount of bias
  from the impact of unemployment which should be considered where policies include
  this factor", "",
  "There may be covariance between lower levels of education and lower wages, along
  with unemployment. It is likely to have in impact on tax per capita or the lower wages
  number, neither of which have been included in the model","",
  "This is a counter-weight to education levels and unemployment, both of which may be higher
  in such communities. This is not necessarily in all areas of low population as there are
  areas, on the outer banks, where many second homes are located that can be a victim to
  burglary and theft. This is expected to explain part of the coefficient
  for population density making the density coefficient less positive","",
  "This is likely to impact higher-density areas, as the population is greater and the
  probability of disparities existing is higher. Therefore, this is another factor that
  would detrimentally impact the density coefficient in models"
)

omv_proxy <- c(
  "None available in this dataset, but arrests for drug-specific crimes are likely to
  be available, and deaths caused by drugs are captured by the CDC", "",
  "While police presence may be an indicator of likelihood that offenses are reported,
  it would not be a strong proxy. Assessing numbers of groups less likely to report crime
  may help (undocumented migrants, uninsured property, counties with high case backlog) or
  a comparison of crimes that are generally under reported, accross the counties","",
  "Use of one of the economic variables may act as proxy, but a better understanding
  of those variables will be necessary","",
  "A combination of young male and minority may be used as a proxy, however this may
  miss pockets of unemployment in other demographics. Additionally, young males may
  be university students in certain counties","",
  "Use of tax per capita is possible, but may also reflect the underlying wage arbitrage in
  a county. Its also not clear what tax this relates to and may be unreliable as
  an income predictor","",
  "A good proxy is not clearly available in this dataset, and may be hard to identify in
  general. Data on church attendance may be useful, as could membership or attendants of
  other civic societies", "",
  "Efforts were made to use the wages in different sectors to understand disparities, but
  were not deemed practical, given the limitations in the understanding of this data as
  outlined in the EDA. Some more detailed tax information within the county population may
  be useful to generate some understanding into this factor"
)
omv_table <- data.frame("Omitted Variable" = omv_items,
                    "Description" = omv_desc,
                    "Inference" = omv_inf,
                    "Proxy Availability" = omv_proxy)

kable(omv_table, booktabs = TRUE) %>%
  kable_styling(font_size = 6,
                full_width = TRUE) %>%
  row_spec(0, bold = TRUE) %>%
  column_spec(1, width = "8em") %>%
  column_spec(2, width = "20em") %>%
  column_spec(3, width = "20em") %>%
  column_spec(4, width = "20em")
```

[^4]: The Offending, Crime and Justice Survey (2003); RECIDIVISM AMONG FEDERAL OFFENDERS: A COMPREHENSIVE OVERVIEW

\newpage

## Conclusion

The models that have been generated suggest that there are some opportunities for policies in the criminal justice system that could make a substantial impact to the levels of crime in North Carolina. There is a strong relationship between crime rates and the probability of arrest for each crime, and the probability of conviction given arrest. Care should be taken when converting these findings to practical strategies and policies, however.

For example, it is clear that the number of arrests per crime impacts crime rates. This may be due to the arrest being close in time to the act of the crime, it has a strong deterrent. However, while developing policies, arrests must continue to be targeted at those who the police have belief committed the crimes. Creating metrics to demonstrate increased arrests may simply incentivize any arrest, increasing the number of wrongful arrests and leading to civil liberty groups filing complaints.

The probability of conviction is a strong measure of police efficiency. If the police are arresting the correct suspects, then they will be found guilty and convicted. A higher level of certainty of the Justice system working to a would-be perpetrator clearly reduces the propensity for carrying out a crime. Again, care must be taken in implementing policies to improve conviction rates so as not to impede the criminal justice system in any way. Pressurizing juries to convict or making the system more difficult for defendants, would increase the conviction rate, but may lead to more wrongful convictions, reduce the confidence in the judiciary and may not have the intended impact on crime rates.

Policies that will help police quickly identify the correct suspects for arrest should help both variables. Equipment for improved forensic analysis and training for this can be provided. Approaches for crime analysis, interviewing witnesses and community surveillance may also be employed. Additionally, reviewing the practices and policies of those counties that do have lower crime rates due to the better rates of arrest and conviction may uncover some best practices to incorporate into policies.

Historically, increasing police numbers are a quick policy decision to reduce crime. While the model presented here might suggest it may actually increase crime, more work should be done to understand this. As mentioned before, the data is panel in nature, and a time series would be more useful in demonstrating the impact of increased policing.

It is also pointed out that areas where there was a higher minority presence in 1980 also appear to exhibit higher rates of crime. There are likely to be bivariate relationships that are impacting this, including poverty and unemployment levels which artificially increase the impact of this coefficient. There could also be offsets as there may be a lower propensity to report crime in minority communities.

One of the more striking findings is that the probability of a custodial sentence does not appear to be a strong influencer of crime rate. This may be a result of the limited breakdown of crimes committed. It is unlikely that a custodial sentence would be given for traffic offenses, vandalism and many petty crimes which form the majority of criminality, and therefore prison will not form a disincentive to commit them. The crimes that are likely to result in a prison sentence would have to be more closely analyzed to understand if the probability of committing that crime and going to prison impact the number of such crimes committed. There are policy opportunities in this space. Since judges are elected in North Carolina, campaigns can be formulated to attempt to elect judges that are hard on crime and have higher precedent of custodial sentencing. There is a crime mix indicator provided in the dataset, however it does not clearly distinguish between those offenses punishable by prison and those that are not, and the results of using it provided limited insights. Some more detailed data on crime will be needed to demonstrate how to incorporate this into policies.

It is also worth mentioning that, due to the difference in the crime levels in the West of the state, there may be more specific policies that would apply there. More rural and sparsely populated communities where families have deeper roots and stronger ties may attract a different type of crime than the mix in the rest of the state.

The number of omitted variables that impact the population density coefficient suggest that there is room for policy development in this area also, but in order to target specific contributors of crime some of those variables must be captured. Providing data on drug abuse, unemployment, poverty and recidivism will help to understand more about the bivariate relationships impacting the coefficient for population density.
